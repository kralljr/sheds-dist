---
title: "Simulation study exploring exposure distribution changes"
output:
  html_document:
    toc: true
    number_sections: true
    theme: cosmo
    toc_depth: 2
---
		  
```{r lib, warning = F, message = F, echo = F}
library(dplyr)
library(reshape2)
library(knitr)
library(ggplot2)
library(RColorBrewer)
library(fda)
library(fda.usc)
library(truncnorm)
library(gridExtra)
library(MESS)
library(refund)
library(glmnet)


fp1 <- "~/Documents/SHEDS"
fp2 <- "~/Dropbox/SHEDS/data"
opts_chunk$set(message = F, fig.align = "center", warning = F, echo = F)

eval1 <- T
figh1 <- 4
figw1 <- 8
```



```{r external}
source("sim_study_fn.R")
source("sim_study_display.R")
source("mcmc_corr.R")
```

Jenna Krall

Revised 9/7/15

The current project is aimed at using distributions of exposure to outdoor pollution as predictors in a health effects regression model.  While previous studies only had access to daily summaries of exposure (e.g. daily mean), recently simulated exposure data has become available and provides a distribution of exposures for each day.  Having exposure distributions for each day will allow us to determine the changes in exposure distribution that are associated with the greatest increases in adverse health outcomes.  Additionally, we can determine the associations between quantiles of the exposure distribution and adverse health outcomes.  This current analysis is focused on the question of how quantiles of the exposure distribution are associated with adverse health outcomes.  Knowing whether some quantiles are more associated with adverse health outcomes can help to develop more targeted public health campaigns.  For example, if the 20\% quantile is most associated with adverse health outcomes, then those individuals who generally have lower exposures to outdoor pollution should be targeted.

This document includes a preliminary simulation study to determine whether using the quantiles of exposure in a functional regression model yields good estimates of the health effects.  One concern is that if using standard regression techniques provides comparable results in this scenario, there is no reason to pursue functional data analysis. 



```{r argv}
naG <- 105
na1 <- 30
argvals2 <- seq(0.05, 0.95, length = na1)
ag1 <- c(0.1, 0.25, 0.5, 0.75, 0.9)


ny <- 100
ns2 <- 4

#disttype1 <- "pois"

disttype1 <- "norm"
sd2 <- 0.001
```

# Description of creating distributions of exposures


In order to perform the simulation study, we first had to generate distributions of exposures for each day.  To start, we assumed that the distribution of exposures on each day was truncN$(15, 1.5^2)$ where the concentrations were truncated below by zero.  The histogram of this distribution is shown below.  Then, we modified this distribution according to how the distributions might change day-to-day, as described in the following sections. 




```{r truncn}
x <- rtruncnorm(10000, a = 0, mean = 15, sd = 1.5)
hist(x, main = "Basic simulated exposure distribution", xlab = "Concentration")

```


## Shift in exposures

We first assume that the distribution of exposures shifts day-to-day with ambient PM2.5.  Therefore, the shape of the true distribution doesn't change, though day-to-day variability in the sampled exposures may change. To accomplish this, for each day, we sampled $s$ from a uniform distribution [-5, 20] to determine the shift.  Then, we added this rate to the originally generated data such that the exposures followed truncN$(15, 1.5^2) + s_t$ for day $t$.

In the first row of plots below, we show the histograms and corresponding quantile plots across days for these set of exposures over time.  For the quantiles, we assume that we sampled 20 quantiles from [0,1]. In the second row of plots, we show the quantile plots again, along with the smoothed functional quantile plots using bsplines with order equal to `r ns2`.


```{r shift, fig.height = figh1, fig.width = figw1}
set.seed(1528)

x1 <- getx(ny, naG, argvals2, typex = "shift", ns1 = ns2)
#ns2 <- 5

plotallx(x1, argvals2)
```

## Long right tail

Another way the distributions in exposure might change is if when PM2.5 increases outside, only those who are in the right tail (e.g. outdoor workers) have increases in exposure.  

To create the long right tail, we sampled from the uniform $[2, 6]$ distribution a shift parameter $a_t$.  Then, we computed $s_t = ((x > 15) * (x - 15) * a_t)^+$.  This positive part expression is simply the concentrations $x$ for concentrations less than the mean (15) and a line with slope $a_t$ for concentrations greater than the mean.  We added $s_t$ to the concentrations $x$ to create distributions with changing right tails. 


```{r longr, fig.height = figh1, fig.width = figw1}
x1 <- getx(ny, naG, argvals2, typex = "longr", ns1 = ns2)


plotallx(x1, argvals2)

```

## Long left tail

The exposures might increase more for the smaller quantiles if, for example, on nice days, office workers or individuals in assisted living make an effort to go outdoors, and therefore increase their exposure.  We generated this distribution of exposures in a similar way to the exposures for the long right tail in the previous section. 


To create the long left tail, we sampled from the uniform $[0, 2]$ distribution a shift parameter $a_t$.  Then, we computed $s_t = ((x < 15) * (15 - x) * -a_t)^+$.  This positive part expression is simply the concentrations $x$ for concentrations greater than the mean (15) and a line with slope $-a_t$ for concentrations less than the mean.  We added $s_t$ to the concentrations $x$ to create distributions with changing left tails. 


```{r longl, fig.height = figh1, fig.width = figw1}
x1 <- getx(ny, naG, argvals2, typex = "longl", ns1 = ns2)


plotallx(x1, argvals2)

```

## Increased exposure variance

We also consider a simulated scenario where the variability of exposures increases on some days, which could be driven by more varied behavior on nice days, where some people do not change their low exposure habits and others go outdoors.  To accomplish this, we generated exposures as truncN$(15, \sigma_t)$, where $\sigma_t$ was allowed to vary from day-to-day.  We chose $\sigma_t$ from a random uniform distribution between 0.3 and 6.  

```{r wide, fig.height = figh1, fig.width = figw1}
x1 <- getx(ny, naG, argvals2, typex = "wide", ns1 = ns2)


plotallx(x1, argvals2)

```


## True exposures


The Atlanta SHEDS data were scaled up from ZCTAs by sampling from each ZCTA proportional to its population (with the largest ZCTA, 30044, sampling all 100 individuals).  There were 193 ZCTAs in the file.  



```{r wtrue, fig.height = figh1, fig.width = figw1}

#Detrend date?

# Get all data
xall <- read.csv(file.path(fp2, "SHEDS_pm_atl.csv"))[, c(2, 4)]


# Get quantiles
quants1 <- tapply(xall$pm, xall$date, quantile, probs = argvals2)
quants2 <- sapply(quants1, function(x) x)

# Get quantiles
quantsREG <- tapply(xall$pm, xall$date, quantile, probs = ag1)
quantsREG <- t(sapply(quantsREG, function(x) x))





# Get in form for ggplot
x1 <- quants2
dates <- unique(xall[, 1])
samp1 <- sample(dates, 100)

# Make smaller data
mxall <- xall[which(xall[, 1] %in% samp1),]


samp1 <- samp1[1]
samp2 <- paste0("x", gsub("-", ".", samp1))


# Get in form for ggplot
d1 <- data.frame(argvals2, x1)
mx <- melt(d1, id.vars = "argvals2")
mx$variable <- tolower(mx$variable)

# Select one day to highlight
mx <- mutate(mx, select1 = ifelse(variable == samp2, "Yes", "No"))
mxall <- mutate(mxall, select1 = ifelse(date == samp1, "Yes", "No"))

# Order so plot highlighted last
lev1 <- mxall$date[order(mxall$select1)]
mxall$date <- factor(mxall$date, levels = unique(lev1))

lev1 <- mx$variable[order(mx$select1)]
mx$variable <- factor(mx$variable, levels = unique(lev1))

# Create density plots of all x's
g1 <- ggplot(data = mxall, aes(x = pm, group = date, colour = select1)) +
  geom_density(aes(size = select1)) + theme_bw() +
  scale_colour_manual(guide = F, values = c("grey80", "red")) +
  scale_size_manual(guide = F, values = c(1, 1.4)) +
  theme(legend.position = "none") +
  xlab("Concentration") + ggtitle("Density plots of personal exposure")

# Create quantile plots of x quantiles
g2 <- ggplot(data = mx, aes(x = argvals2, y = value, group = variable, colour = select1)) +
  geom_line(aes(size = select1)) + theme_bw() +

  scale_colour_manual(guide = F, values = c("grey80", "red")) +
  scale_size_manual(guide = F, values = c(1, 1.4)) +

  theme(legend.position = "none") + xlab("Quantile") +
  ylab("Concentration") + ggtitle("Plot of quantiles of concentration")

# Arrange output for plots 
grid.arrange(g1, g2, ncol = 2)




# Save output
x1 <- list()
x1$xall <- t(xall)

xM <- quantsREG[, "50%"]

x1$x1 <- quants2
x1$xREG <- t(quantsREG)


x1$xfn <- getxfn(x1$x1, argvals2, ns1 = ns2) 
x1$basis1 <- x1$xfn$basis1
x1$xfn <- x1$xfn$xfn
x1$xM <- xM

xtrue <- x1

```

# Beta functions


We consider 6 functions for beta(q) for a constant value $v$:

1. Constant beta, $\beta$(q) = $v$
2. Larger beta for low and high quantiles, $\beta$(q) = $v$ + 1/4 * (q - 0.5)^2
3. Larger beta for low quantiles,  $\beta$(q) = $v$ + 1/10 * exp(q * -7)
4. Larger beta for high quantiles, $\beta$(q) = $v$ + 1 / 10000 * exp(q * 7)  

These beta functions were chosen to reflect the scenarios where the association doesn't vary by quantile (constant beta), the lower and upper quantiles have a greater effect (if these represent more susceptible individuals), the low quantiles have a greater effect, and the high quantiles have a greater effect.  These beta functions are shown below in the results as the black curves.



# Generating outcome data

Once we chose a distribution of exposures and a beta function, we generated outcomes y as Poisson($\mu$) where $\mu=\exp\{\beta_0 + \int_0^1 \beta(q) X(q) dq\}$ or Normal($\mu$, 0.01), where $\mu=\beta_0 + \int_0^1 \beta(q) X(q)$.  The integral is approximated by $\frac{1}{N}\sum_{i=1}^N \beta_i X_i$ where $N$ is the number of quantiles included and $X_i$ is the concentration at quantile $i$.  

<!--To approximate the integral, we multiplied the observed x values by the beta function at the observed quantiles and computed the area under the curve.
-->

# Simulation study

## Methods

We generated quantile data from our exposures for 20 quantiles from 0 to 1.  For each simulated scenario (choice of distributions for exposures, and choice of $\beta(q)$), we simulated outcomes $Y$ using poisson or gaussian distributions.   


To compare our results with more traditional approaches, we fit the quantiles using both univariate regression (green) and multivariate regression (orange), using linear or log-linear regression models, depending on how $y$ was simulated.  We assumed that the researcher selected those quantiles of primary interest: 10\%, 25\%, 50\%, 75\%, 90\%.   

## Results









```{r getx, eval = T, fig.height = 10, fig.width = 15}


ny <- 1000

  
# for each reasonable comb
ts1 <- c("constant", "high", "low", "high", "low", "x2", "high", "low", "x2")
xs1 <- c("shift", "longr", "longl", "wide", "wide", "wide", "true", "true", "true")
xs1 <- data.frame(xs1, c(1, 2, 3, 4, 4, 4, 5, 5, 5))


dt1 <- "norm"


tx <- unique(xs1[, 1])

x1use <- list()
# For each x
for(xi in 1 : 5) {

  if(xi < 5) {
    x1use[[xi]] <- getx(ny, naG, argvals2, argvalslr = ag1, typex = tx[xi], ns1 = ns2)
  } else if (xi == 5){  
    x1use[[xi]] <- xtrue
}}




```




```{r setall}
cn <- c("X", "Est", "SE", "Zval", "Pval", "Type1", "Reg")
std1 <- T
lb1 <- -0.1
ub1 <- 0.25
```






### No shift




#### Small betas
```{r beta1, eval = T, fig.height = 10, fig.width = 15}


scaleb <- 1/2
shift1 <- 0

runsim1 <- runsim(x1use, xs1, ts1, cn, scaleb = scaleb, val1 = shift1, disttype1 = dt1, lb1 = lb1, ub1 = ub1, argvalslr = )                    
gfun(runsim1, lb1 = lb1, ub1 = ub1)

save(runsim1, file = "sbeta_noshift.RData")

tab1 <- data.frame(levels(runsim1$xfull$Type1), round(runsim1$med, 3))
colnames(tab1) <- c("Type", "Beta_median")
kable(tab1)
```


#### Larger betas
```{r beta2, eval = T, fig.height = 10, fig.width = 15}
scaleb <- 1

runsim1 <- runsim(x1use, xs1, ts1, cn, scaleb = scaleb, val1 = shift1, disttype1 = dt1, lb1 = lb1, ub1 = ub1)                    
gfun(runsim1, lb1 = lb1, ub1 = ub1)


save(runsim1, file = "lbeta_noshift.RData")

tab1 <- data.frame(levels(runsim1$xfull$Type1), round(runsim1$med, 3))
colnames(tab1) <- c("Type", "Beta_median")
kable(tab1)
```





### Shift

#### Small betas
```{r beta3, eval = T, fig.height = 10, fig.width = 15}


scaleb <- 1/2
shift1 <- 0.01

runsim1 <- runsim(x1use, xs1, ts1, cn, scaleb = scaleb, val1 = shift1, disttype1 = dt1, lb1 = lb1, ub1 = ub1)                    
gfun(runsim1, lb1 = lb1, ub1 = ub1)


save(runsim1, file = "sbeta_shift.RData")


tab1 <- data.frame(levels(runsim1$xfull$Type1), round(runsim1$med, 3))
colnames(tab1) <- c("Type", "Beta_median")
kable(tab1)
```


#### Larger betas
```{r beta4, eval = T, fig.height = 10, fig.width = 15}
scaleb <- 1

runsim1 <- runsim(x1use, xs1, ts1, cn, scaleb = scaleb, val1 = shift1, disttype1 = dt1, lb1 = lb1, ub1 = ub1)                    
gfun(runsim1, lb1 = lb1, ub1 = ub1)


save(runsim1, file = "lbeta_shift.RData")

tab1 <- data.frame(levels(runsim1$xfull$Type1), round(runsim1$med, 3))
colnames(tab1) <- c("Type", "Beta_median")
kable(tab1)

```





```{r, eval = F}
#8/31/15
# stdize, don't scale

# try by hand
bf <- getbeta("high")


ag1 <- c(0.1, 0.25, 0.5, 0.75, 0.9)
ag1 <- argvals2

betas1 <- bf(ag1)  

xuse1 <- x1use[[4]]$xall  
xuse <- t(apply(xuse1,  2, quantile, probs = ag1))


linfun <-  rowSums(sweep(xuse, 2, betas1, "*"))
set.seed(10)
y <- rpois(ny, exp(linfun))


#stdize
mn1 <- apply(xuse, 2, mean)
sd1 <- apply(xuse, 2, sd)
xuse <- sweep(xuse, 2, mn1, "-")
xuse <- sweep(xuse, 2, sd1, "/")




#check reality
meds <- apply(xuse1, 2, median)
summary(linfun / meds)

glm1 <- glm(y ~ -1 + meds, family = "poisson")
exp(glm1$coef * 8)


dat1 <- data.frame(y, xuse)
p1 <-  paste0("x", seq(1, ncol(dat1) - 1))
colnames(dat1)[-1] <- p1
eqn1 <- paste("y ~ ", paste(p1, collapse = " + "))
glm1 <- glm(eval(eqn1), data = dat1, family = "poisson")
gc1 <- glm1$coef[-1]
plot(ag1, gc1, ylim = c(-0.5, .5))
points(ag1, betas1, col = "red")
sglm1 <- summary(glm1)$coef[-1, ]
lb <- sglm1[, 1] - 1.96 * sglm1[, 2]

ub <- sglm1[, 1] + 1.96 * sglm1[, 2]
segments(x0 = ag1, y0 = lb, y1 = ub, col = 1)
```
